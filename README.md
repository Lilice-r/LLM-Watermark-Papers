# LLM Watermark Papers

- [LLM Watermark Papers](#llm-watermark-papers)
  - [Survey](#survey)
  - [LLM Watermark](#llm-watermark)
    - [One-bit](#one-bit)
    - [Multi-bit](#multi-bit)
  - [Backdoor Watermark Since 2024](#backdoor-watermark-since-2024)

## Survey
- **A Survey of Text Watermarking in the Era of Large Language Models** [[paper]](https://dl.acm.org/doi/pdf/10.1145/3691626) ![](https://img.shields.io/badge/ACMComputingSurveys-orange) 
- **SoK: Watermarking for AI-Generated Content** [[paper]](https://arxiv.org/pdf/2411.18479) ![](https://img.shields.io/badge/S&P%202025-orange)


## LLM Watermark
> **Note:** We believe that KGW is the starting point of LLM Watermark, so we only collect watermarking work after KGW.

### One-bit
- **A Watermark for Large Language Models** [[paper]](https://arxiv.org/pdf/2301.10226) ![](https://img.shields.io/badge/ICML%202023-OutstandingPaper-orange)

- **WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models** [[paper]](https://arxiv.org/pdf/2311.07138.pdf) ![](https://img.shields.io/badge/ACL%202024-orange) 

- **Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models** [[paper]](https://aclanthology.org/2024.acl-long.226.pdf) ![](https://img.shields.io/badge/ACL%202024-orange) 

- **GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick** [[paper]](https://arxiv.org/pdf/2402.12948.pdf) ![](https://img.shields.io/badge/ACL%202024-orange)

- **Bypassing LLM Watermarks with Color-Aware Substitutions** [[paper]](https://aclanthology.org/2024.acl-long.464.pdf) ![](https://img.shields.io/badge/ACL%202024-orange) 

- **Who Wrote this Code? Watermarking for Code Generation** [[paper]](https://arxiv.org/pdf/2305.15060) ![](https://img.shields.io/badge/ACL%202024-orange) 

- **Subtle Signatures, Strong Shields: Advancing Robust and Imperceptible Watermarking in Large Language Models** [[paper]](https://aclanthology.org/2024.findings-acl.327.pdf) ![](https://img.shields.io/badge/ACL%202024%20Findings-orange) 

- **Duwak: Dual Watermarks in Large Language Models** [[paper]](https://arxiv.org/pdf/2403.13000) ![](https://img.shields.io/badge/ACL%202024%20Findings-orange) 


- **k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text** [[paper]](https://arxiv.org/pdf/2402.11399.pdf) ![](https://img.shields.io/badge/ACL%202024%20Findings-orange) 


- **SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation** [[paper]](https://arxiv.org/pdf/2310.03991.pdf) ![](https://img.shields.io/badge/NAACL%202024-orange) 


- **A Robust Semantics-based Watermark for Large Language Model against Paraphrasing** [[paper]](https://arxiv.org/pdf/2311.08721.pdf) ![](https://img.shields.io/badge/NAACL%202024%20Findings-orange)

- **WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models** [[paper]](https://arxiv.org/pdf/2403.19548) ![](https://img.shields.io/badge/NAACL%202024%20Findings-orange)


- **PostMark: A Robust Blackbox Watermark for Large Language Models** [[paper]](https://arxiv.org/pdf/2406.14517) ![](https://img.shields.io/badge/EMNLP%202024-orange)


- **Context-aware Watermark with Semantic Balanced Green-red Lists for Large Language Models** [[paper]](https://aclanthology.org/2024.emnlp-main.1260/) ![](https://img.shields.io/badge/EMNLP%202024-orange)

- **GuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack** [[paper]](https://aclanthology.org/2024.findings-emnlp.441.pdf) ![](https://img.shields.io/badge/EMNLP%202024%20Findings-orange)


- **A Semantic Invariant Robust Watermark for Large Language Models** [[paper]](https://openreview.net/pdf?id=6p8lpe4MNf) ![](https://img.shields.io/badge/ICLR%202024-orange)


- **Unbiased Watermark for Large Language Models** [[paper]](https://openreview.net/pdf?id=uWVC5FVidc) ![](https://img.shields.io/badge/ICLR%202024-orange)

- **Provable Robust Watermarking for AI-Generated Text** [[paper]](https://openreview.net/pdf?id=SsmT8aO45L) ![](https://img.shields.io/badge/ICLR%202024-orange) 

- **On the Reliability of Watermarks for Large Language Models** [[paper]](https://openreview.net/pdf?id=DEJIDCmWOz) ![](https://img.shields.io/badge/ICLR%202024-orange)

- **On the Learnability of Watermarks for Language Models** [[paper]](https://openreview.net/pdf?id=9k0krNzvlV) ![](https://img.shields.io/badge/ICLR%202024-orange) 

- **An Unforgeable Publicly Verifiable Watermark for Large Language Models** [[paper]](https://openreview.net/pdf?id=gMLQwKDY3N) ![](https://img.shields.io/badge/ICLR%202024-orange) 


- **No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design Choices** [[paper]](https://openreview.net/pdf?id=rIOl7KbSkv) ![](https://img.shields.io/badge/NeurIPS%202024-orange) 


- **Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models** [[paper]](https://openreview.net/pdf?id=6YKMBUiIsG) ![](https://img.shields.io/badge/NeurIPS%202024-orange) 


- **Watermarking Makes Language Models Radioactive** [[paper]](https://arxiv.org/pdf/2402.14904.pdf) ![](https://img.shields.io/badge/NeurIPS%202024-orange) 


- **WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off** [[paper]](https://arxiv.org/pdf/2403.04808) ![](https://img.shields.io/badge/NeurIPS%202024-orange) 



- **Optimizing Watermarks for Large Language Models** [[paper]](https://arxiv.org/pdf/2312.17295) ![](https://img.shields.io/badge/ICML%202024-orange)
  

- **Watermark Stealing in Large Language Models** [[paper]](https://arxiv.org/pdf/2402.19361) ![](https://img.shields.io/badge/ICML%202024-orange)

- **Adaptive Text Watermark for Large Language Models** [[paper]](https://arxiv.org/pdf/2401.13927.pdf) ![](https://img.shields.io/badge/ICML%202024-orange)


- **Watermarks in the Sand: Impossibility of Strong Watermarking for Language Models** [[paper]](https://arxiv.org/pdf/2311.04378) ![](https://img.shields.io/badge/ICML%202024-orange)

- **Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models** [[paper]](https://arxiv.org/pdf/2402.18059.pdf) ![](https://img.shields.io/badge/ICML%202024-orange) 

- **A Resilient and Accessible Distribution-Preserving Watermark for Large Language Models** [[paper]](https://arxiv.org/pdf/2310.07710.pdf) ![](https://img.shields.io/badge/ICML%202024-orange) 

- **Undetectable Watermarks for Language Models** [[paper]](https://proceedings.mlr.press/v247/christ24a/christ24a.pdf) ![](https://img.shields.io/badge/PLMR%202024-orange)


- **Robust Distortion-free Watermarks for Language Models** [[paper]](https://openreview.net/pdf?id=FpaCL1MO2C) ![](https://img.shields.io/badge/TMLR%202024-orange) 

- **Scalable watermarking for identifying large language model outputs** [[paper]](https://www.nature.com/articles/s41586-024-08025-4) ![](https://img.shields.io/badge/Nature%202024-orange) 

- **Ensemble Watermarks for Large Language Models** [[paper]](https://arxiv.org/pdf/2411.19563) ![](https://img.shields.io/badge/ACL%202025-orange) 

- **MorphMark: Flexible Adaptive Watermarking for Large Language Models** [[paper]](https://aclanthology.org/2025.acl-long.240.pdf) ![](https://img.shields.io/badge/ACL%202025-orange) 


- **Efficiently Identifying Watermarked Segments in Mixed-Source Texts** [[paper]](https://aclanthology.org/2025.acl-long.316.pdf) ![](https://img.shields.io/badge/ACL%202025-orange) 


- **Watermarking Large Language Models: An Unbiased and Low-risk Method** [[paper]](https://aclanthology.org/2025.acl-long.391.pdf) ![](https://img.shields.io/badge/ACL%202025-orange) 


- **From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models** [[paper]](https://aclanthology.org/2025.acl-long.509.pdf) ![](https://img.shields.io/badge/ACL%202025-orange) 


- **Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?** [[paper]](https://aclanthology.org/2025.acl-long.648.pdf) ![](https://img.shields.io/badge/ACL%202025-orange) 


- **Improved Unbiased Watermark for Large Language Models** [[paper]](https://aclanthology.org/2025.acl-long.1005.pdf) ![](https://img.shields.io/badge/ACL%202025-orange) 


- **Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking** [[paper]](https://aclanthology.org/2025.acl-long.1436.pdf) ![](https://img.shields.io/badge/ACL%202025-orange) 


- **$B^4$: A Black-Box Scrubbing Attack on LLM Watermarks**[[paper]](https://aclanthology.org/2025.naacl-long.460/)![](https://img.shields.io/badge/NAACL%202025-orange)
  
- **WaterPool: A Language Model Watermark Mitigating Trade-Offs among Imperceptibility, Efficacy and Robustness**[[paper]](https://aclanthology.org/2025.naacl-long.209/) ![](https://img.shields.io/badge/NAACL%202025-orange)


- **WaterSeeker: Pioneering Efficient Detection of Watermarked Segments in Large Documents** [[paper]](https://aclanthology.org/2025.findings-naacl.156.pdf) ![](https://img.shields.io/badge/NAACL%202025%20Findings-orange) 

- **From Intentions to Techniques: A Comprehensive Taxonomy and Challenges in Text Watermarking for Large Language Models** [[paper]](https://aclanthology.org/2025.findings-naacl.343.pdf) ![](https://img.shields.io/badge/NAACL%202025%20Findings-orange) 
  
- **Lost in Overlap: Exploring Logit-based Watermark Collision in LLMs** [[paper]](https://arxiv.org/pdf/2403.10020) ![](https://img.shields.io/badge/NAACL%202025%20Findings-orange) 


- **A Watermark for Order-Agnostic Language Models Ward: Provable RAG Dataset Inference via LLM Watermarks** [[paper]](https://openreview.net/pdf?id=Nlm3Xf0W9S) ![](https://img.shields.io/badge/ICLR%202025-orange)

- **Can Watermarked LLMs be Identified by Users via Crafted Prompts?** [[paper]](https://openreview.net/pdf?id=ujpAYpFDEA) ![](https://img.shields.io/badge/ICLR%202025-orange)

- **Can Watermarks be Used to Detect LLM IP Infringement For Free?**[[paper]](https://openreview.net/pdf?id=KRMSH1GxUK) ![](https://img.shields.io/badge/ICLR%202025-orange)
  
- **Permute-and-Flip: An optimally stable and watermarkable decoder for LLMs**[[paper]](https://openreview.net/pdf?id=YyVVicZ32M) ![](https://img.shields.io/badge/ICLR%202025-orange)
  
- **Black-Box Detection of Language Model Watermarks**[[paper]](https://arxiv.org/pdf/2405.20777) ![](https://img.shields.io/badge/ICLR%202025-orange)



- **Optimizing Adaptive Attacks against Watermarks for Language Models**[[paper]](https://openreview.net/pdf?id=AsODat0dkE) ![](https://img.shields.io/badge/ICML%202025-orange)
  
- **BiMark: Unbiased Multilayer Watermarking for Large Language Models**[[paper]](https://openreview.net/pdf?id=Zvyb3WAg03) ![](https://img.shields.io/badge/ICML%202025-orange)
  
- **Discovering Spoofing Attempts on Language Model Watermarks**[[paper]](https://openreview.net/attachment?id=hSCxEZLvxI&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)
  
- **Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks**[[paper]](https://openreview.net/attachment?id=fE3kgW7kMp&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)

- **Lightweight-Mark: Rethinking Deep Learning-Based Watermarking**[[paper]](https://openreview.net/attachment?id=ag3uveGZCb&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)

- **De-mark: Watermark Removal in Large Language Models**[[paper]](https://openreview.net/attachment?id=5dF4mqVVqK&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)
  
- **GaussMark: A Practical Approach for Structural Watermarking of Language Models**[[paper]](https://openreview.net/attachment?id=YG3DbpAQBf&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)

- **An End-to-End Model For Logits Based Large Language Models Watermarking**[[paper]](https://openreview.net/attachment?id=9sNiCqi2RD&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)


- **RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models** [[paper]](https://arxiv.org/pdf/2501.05249) ![](https://img.shields.io/badge/CCS%202025-orange)

- **ModelShield: Adaptive and Robust Watermark Against Model Extraction Attack** [[paper]](https://arxiv.org/pdf/2405.02365) ![](https://img.shields.io/badge/TIFS%202025-orange)


- **Watermarking Language Models for Many Adaptive Users** [[paper]](https://arxiv.org/pdf/2405.11109) ![](https://img.shields.io/badge/S&P%202025-orange) 


### Multi-bit
- **Three Bricks to Consolidate Watermarks for Large Language Models** [[paper]](https://arxiv.org/pdf/2308.00113) ![](https://img.shields.io/badge/WIFS%202023-orange)


- **Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs** [[paper]](https://openreview.net/pdf?id=JYu5Flqm9D) ![](https://img.shields.io/badge/ICLR%202024-orange) 

- **Advancing Beyond Identification: Multi-bit Watermark for Large Language Models** [[paper]](https://arxiv.org/pdf/2308.00221) ![](https://img.shields.io/badge/NAACL%202024-orange) 

- **Waterfall: Scalable Framework for Robust Text Watermarking and Provenance for LLMs** [[paper]](https://aclanthology.org/2024.emnlp-main.1138.pdf) ![](https://img.shields.io/badge/EMNLP%202024-orange) 

- **CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code** [[paper]](https://aclanthology.org/2024.findings-emnlp.541.pdf) ![](https://img.shields.io/badge/EMNLP%202024%20Findings-orange)

- **REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models** [[paper]](https://arxiv.org/pdf/2310.12362.pdf) ![](https://img.shields.io/badge/USENIX%202024-orange) 


- **Provably Robust Multi-bit Watermarking for AI-generated Text** [[paper]](https://arxiv.org/pdf/2401.16820.pdf) ![](https://img.shields.io/badge/USENIX%202025-orange)


- **Robust Multi-bit Text Watermark with LLM-based Paraphrasers**[[paper]](https://openreview.net/attachment?id=DVjkling5x&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)

- **StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models**[[paper]](https://openreview.net/attachment?id=dktpDfUTtj&name=pdf) ![](https://img.shields.io/badge/ICML%202025-orange)

## Backdoor Watermark Since 2024
- **WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection** [[paper]](https://aclanthology.org/2024.acl-long.725.pdf) ![](https://img.shields.io/badge/ACL%202024-orange) 

- **Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark** [[paper]](https://openreview.net/pdf?id=cObFETcoeW) ![](https://img.shields.io/badge/ICLR%202024-orange) 

- **ZeroMark: Towards Dataset Ownership Verification without Disclosing Watermark** [[paper]](https://openreview.net/pdf?id=Eyyt3ZmNV6) ![](https://img.shields.io/badge/NeurIPS%202024-orange) 


- **SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by Self-Supervised
Learning**[[paper]](https://www.ndss-symposium.org/wp-content/uploads/2024-374-paper.pdf) ![](https://img.shields.io/badge/NDSS%202024-orange) 

- **Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data** [[paper]](https://arxiv.org/pdf/2309.03466) ![](https://img.shields.io/badge/CCS%202024-orange) 

- **TabularMark: Watermarking Tabular Datasets for Machine Learning** [[paper]](https://arxiv.org/pdf/2406.14841) ![](https://img.shields.io/badge/CCS%202024-orange) 

- **MEA-Defender: A Robust Watermark against Model Extraction Attack** [[paper]](https://arxiv.org/pdf/2401.15239) ![](https://img.shields.io/badge/S&P%202024-orange) 
  
- **PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification** [[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10646612) ![](https://img.shields.io/badge/S&P%202024-orange) 

- **DeepEclipse: How to Break White-Box DNN-Watermarking Schemes** [[paper]](https://www.usenix.org/system/files/usenixsecurity24-pegoraro.pdf) ![](https://img.shields.io/badge/USENIX%202024-orange) 

- **PointNCBW: Toward Dataset Ownership Verification for Point Clouds via Negative Clean-Label Backdoor Watermark** [[paper]](https://arxiv.org/pdf/2408.05500) ![](https://img.shields.io/badge/TIFS%202024-orange)

- **Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution** [[paper]](https://www.ndss-symposium.org/wp-content/uploads/2025-338-paper.pdf) ![](https://img.shields.io/badge/NDSS%202025-orange) 






